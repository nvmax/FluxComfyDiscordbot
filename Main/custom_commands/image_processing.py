import discord
import logging
import uuid
from typing import Optional, List, Any, Dict

# Third-party imports
from discord import Interaction

# Local application imports
from Main.utils import load_json, save_json, generate_random_seed
from .workflow_utils import update_workflow
from config import fluxversion

logger = logging.getLogger(__name__)

async def process_image_request(interaction: discord.Interaction, prompt: str, resolution: str, upscale_factor: int = 1, seed: Optional[int] = None, workflow: Optional[Dict] = None, workflow_filename: Optional[str] = None):
    """Process a standard image generation request without prompt enhancement."""
    try:
        # Only defer if we haven't responded yet (i.e., no warning message was sent)
        if not interaction.response.is_done():
            await interaction.response.defer(ephemeral=False)
        
        # If no workflow is provided, handle standard image generation
        if workflow is None:
            # Show LoRA selection view
            from .views import LoRAView  # Import here to avoid circular import
            lora_view = LoRAView(interaction.client)
            lora_message = await interaction.followup.send(
                "Please select the LoRAs you want to use:",
                view=lora_view,
                ephemeral=True
            )
            
            # Wait for LoRA selection
            await lora_view.wait()
            
            if not hasattr(lora_view, 'has_confirmed') or not lora_view.has_confirmed:
                await lora_message.edit(content="Selection cancelled or timed out.", view=None)
                return
                
            selected_loras = lora_view.selected_loras
            logger.debug(f"Selected LoRAs: {selected_loras}")
            
            try:
                await lora_message.delete()
            except discord.NotFound:
                pass
            
            # Get LoRA trigger words for currently selected LoRAs
            lora_config = load_json('lora.json')
            additional_prompts = []
            for lora_file in selected_loras:
                lora_info = next(
                    (l for l in lora_config['available_loras'] if l['file'] == lora_file),
                    None
                )
                if lora_info and lora_info.get('add_prompt') and lora_info['add_prompt'].strip():
                    additional_prompts.append(lora_info['add_prompt'].strip())
            
            # Construct final prompt with new trigger words
            full_prompt = prompt
            if additional_prompts:
                if not full_prompt.endswith(','):
                    full_prompt += ','
                full_prompt += ' ' + ', '.join(additional_prompts)
            
            full_prompt = full_prompt.strip(' ,')
            logger.debug(f"Final prompt with LoRA triggers: {full_prompt}")
            
            # Use provided seed or generate new one
            current_seed = seed if seed is not None else generate_random_seed()
            
            workflow = load_json(fluxversion)
            request_uuid = str(uuid.uuid4())
            
            workflow = update_workflow(
                workflow,
                full_prompt,
                resolution,
                selected_loras,
                upscale_factor,
                current_seed
            )

            workflow_filename = f'flux3_{request_uuid}.json'
            save_json(workflow_filename, workflow)
        else:
            # Use the provided workflow and filename
            if workflow_filename is None:
                workflow_filename = f'flux3_{str(uuid.uuid4())}.json'
            save_json(workflow_filename, workflow)
            current_seed = seed
            full_prompt = prompt
            
            # Extract LoRAs from workflow for PuLID requests
            selected_loras = []
            if workflow.get('73') and workflow['73'].get('inputs'):
                lora_inputs = workflow['73']['inputs']
                for key in lora_inputs:
                    if key.startswith('lora_') and isinstance(lora_inputs[key], dict):
                        lora = lora_inputs[key].get('lora')
                        if lora:
                            selected_loras.append(lora)

        # Send processing message
        original_message = await interaction.followup.send(
            "ðŸ”„ Starting generation process...",
            ephemeral=False
        )

        # Create request item
        from .models import RequestItem  # Import here to avoid circular import
        request_item = RequestItem(
            id=str(interaction.id),
            user_id=str(interaction.user.id),
            channel_id=str(interaction.channel.id),
            interaction_id=str(interaction.id),
            original_message_id=str(original_message.id),
            prompt=full_prompt,
            resolution=resolution,
            loras=selected_loras,
            upscale_factor=upscale_factor,
            workflow_filename=workflow_filename,
            seed=current_seed,
            is_pulid=workflow_filename and workflow_filename.lower().startswith('pulid') 
        )
        await interaction.client.subprocess_queue.put(request_item)
        
    except Exception as e:
        logger.error(f"Error in process_image_request: {str(e)}", exc_info=True)
        await interaction.followup.send(
            f"An error occurred while processing your request: {str(e)}",
            ephemeral=True
        )
